<div align="center">
<h1>Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation</h1>


[Zhe Kong*](https://scholar.google.com/citations?user=4X3yLwsAAAAJ&hl=zh-CN) 路 [Feng Gao*](https://scholar.google.com/citations?user=lFkCeoYAAAAJ) 路[Yong Zhang](https://yzhang2016.github.io/)<sup>&#9993;</sup> 路 [Zhuoliang Kang](https://scholar.google.com/citations?user=W1ZXjMkAAAAJ&hl=en) 路 [Xiaoming Wei](https://scholar.google.com/citations?user=JXV5yrZxj5MC&hl=zh-CN) 路 [Xunliang Cai](https://openreview.net/profile?id=~Xunliang_Cai1)  

[Guanying Chen](https://guanyingc.github.io/) 路 [Wenhan Luo](https://whluo.github.io/)<sup>&#9993;</sup>

<sup>*</sup>Equal Contribution
<sup>&#9993;</sup>Corresponding Authors


<a href='https://meigen-ai.github.io/multi-talk/'><img src='https://img.shields.io/badge/Project-Page-green'></a>
<a href='https://arxiv.org/abs/2505.22647'><img src='https://img.shields.io/badge/Technique-Report-red'></a>
</div>

> **TL; DR:**  MultiTalk is an audio-driven video generation model

<p align="center">
  <img src="assets/pipe.png">
</p>



##  Introduction

We propose **MultiTalk** , a novel framework for audio-driven multi-person conversational video generation. Given a multi-stream audio input, a reference image and a prompt, MultiTalk generates a video containing interactions following the prompt, with consistent lip motions aligned with the audio.


##  Latest News

* May 29, 2025:  We release the [Technique-Report](https://arxiv.org/abs/2505.22647) of **MultiTalk** 
* May 29, 2025:  We release the [project page](https://meigen-ai.github.io/multi-talk/) of **MultiTalk** 


##  Todo List

- [x] Release the technical report
- [ ] Inference
- [ ] Checkpoints
